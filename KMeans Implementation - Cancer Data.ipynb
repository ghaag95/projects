{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458 241\n",
      "465 234\n",
      "Error B: 2.366%\t\tError M: 7.692%\t\tTotal Error: 4.149%\n",
      "---------------------------------------Final Means-------------------------------------------\n",
      "mu2:  3.043010752688 1.301075268817 1.443010752688 1.337634408602 2.088172043011 1.296774193548 2.103225806452 1.251612903226 1.109677419355\n",
      "mu4:  7.149572649573 6.777777777778 6.713675213675 5.726495726496 5.457264957265 7.837606837607 6.089743589744 6.076923076923 2.542735042735\n",
      "\n",
      "\n",
      "         ID  class  Predicted Class\n",
      "0   1000025      2                2\n",
      "1   1002945      2                4\n",
      "2   1015425      2                2\n",
      "3   1016277      2                4\n",
      "4   1017023      2                2\n",
      "5   1017122      4                4\n",
      "6   1018099      2                2\n",
      "7   1018561      2                2\n",
      "8   1033078      2                2\n",
      "9   1033078      2                2\n",
      "10  1035283      2                2\n",
      "11  1036172      2                2\n",
      "12  1041801      4                2\n",
      "13  1043999      2                2\n",
      "14  1044572      4                4\n",
      "15  1047630      4                2\n",
      "16  1048672      2                2\n",
      "17  1049815      2                2\n",
      "18  1050670      4                4\n",
      "19  1050718      2                2\n"
     ]
    }
   ],
   "source": [
    "#Final Project Phase 3\n",
    "#Program implements k-means clustering algorithm without using SKLearn package and calculates error rates of my clustering algorithm\n",
    "#date: 12/5/2020\n",
    "#author: Glenn Haag\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "def initialize(df):\n",
    "    \n",
    "    #I played around with the seed for the RNG and found most seeds would get me 15 or 16 correct predicted classes\n",
    "    #this one gets 16 correct, so I stuck with it\n",
    "    random.seed(33333)\n",
    "    \n",
    "    #pick a random row of the dataframe to serve as the initial u2 based on the seed of the RNG\n",
    "    u2 = df.loc[random.randint(0,698)]\n",
    "    \n",
    "    #set u4 = u2 so that I can use the below logic\n",
    "    u4 = u2\n",
    "    \n",
    "    #make sure it doesnt pick the same data\n",
    "    while(u4.equals(u2)):\n",
    "        #pick random row for the initial u4 the same as above\n",
    "        u4 = df.loc[random.randint(0,698)]\n",
    "    \n",
    "    return u2, u4\n",
    "\n",
    "def assignment(u2, u4, df):\n",
    "    \n",
    "    #pred_class is a list of all the predicted class values\n",
    "    #if a row of the df has pred_class == 2, it is in cluster 2, pred_class == 4 means cluster 4\n",
    "    pred_class = []\n",
    "    \n",
    "    #dist2 is distance from u2, dist4 is distance from u4\n",
    "    dist2 = 0\n",
    "    dist4 = 0\n",
    "    \n",
    "    #for each data point in the dataframe\n",
    "    for j in range(len(df.index)):\n",
    "        \n",
    "        #for each of the 9 characteristics\n",
    "        for k in range(9):\n",
    "            \n",
    "            #calculate the distance to each of the means\n",
    "            dist2 += (u2[k+1] - df.iloc[j,k+1]) ** 2 \n",
    "            dist4 += (u4[k+1] - df.iloc[j, k+1]) ** 2\n",
    "            \n",
    "        #finish distance calculation by taking sqrt of the sum of the distances from each of the dimensions\n",
    "        dist2 = math.sqrt(dist2)\n",
    "        dist4 = math.sqrt(dist4)\n",
    "        \n",
    "        #if the distance to u2 is less than or equal to the distance to u4, assign to cluster 2 and vice versa\n",
    "        #Cluster 4 gets the data point in the event the distances are exactly equal\n",
    "        #I chose for cluster 4 to get the equidistant ones because I think it's better to be safe\n",
    "        #and classify the tumor as malignant in the case where it's not clear\n",
    "        \n",
    "        if(dist2 < dist4):\n",
    "            pred_class.append(2)\n",
    "            \n",
    "        else:\n",
    "            pred_class.append(4)\n",
    "            \n",
    "        #reset the distance variables after every datapoint is assigned\n",
    "        dist2 = 0\n",
    "        dist4 = 0\n",
    "    \n",
    "    return pred_class\n",
    "    \n",
    "def recalculation(df, u2, u4):\n",
    "       \n",
    "    #Counter variables for the column sums and lengths of each cluster\n",
    "    c2_sum = 0\n",
    "    c4_sum = 0\n",
    "    c2_len = 0\n",
    "    c4_len = 0\n",
    "    \n",
    "    for n in range(9):\n",
    "        for m in range(len(df.index)):\n",
    "            #if the predicted class == 2 (the data is in cluster 2)\n",
    "            if(df.iloc[m, 11] == 2):\n",
    "                #sum each column of the a2-a10 data\n",
    "                c2_sum += df.iloc[m, n+1]\n",
    "                if(n == 0):\n",
    "                    #on the first pass find how many points are in cluster 2\n",
    "                    c2_len += 1\n",
    "            #elif the predicted class == 4 (the data is in cluster 4)\n",
    "            elif(df.iloc[m, 11] == 4):\n",
    "                #sum each column of the a2-a10 data\n",
    "                c4_sum += df.iloc[m, n+1]\n",
    "                #on the first pass find how many points are in cluster 4\n",
    "                if(n == 0):\n",
    "                    c4_len += 1\n",
    "        #the new mean for cluster 2 = the sum of the column(a2, a3 etc), divided by the number of pts in that cluster\n",
    "        #protect against divide by 0, in the very rare case all points are put in one cluster\n",
    "        if(c2_len > 0):\n",
    "            u2[n+1] = c2_sum/c2_len\n",
    "        if(c4_len > 0):\n",
    "            u4[n+1] = c4_sum/c4_len\n",
    "        #reset the column sum value and continue until a2-a10 means are all calculated\n",
    "        c2_sum = 0\n",
    "        c4_sum = 0\n",
    "        \n",
    "    #return the means (list of means of each column)  \n",
    "    return u2, u4\n",
    "\n",
    "#~~~~~~~~~THIS FUNCTION CORRESPONDS TO FP PART 3~~~~~~~~~~\n",
    "def errorRate(df):\n",
    "    \n",
    "    #counter variables\n",
    "    errorB_count = 0\n",
    "    errorM_count = 0\n",
    "    totalPredB = 0\n",
    "    totalPredM = 0\n",
    "    totalB = 0\n",
    "    totalM = 0\n",
    "    \n",
    "    #for all rows in the dataframe\n",
    "    for n in range(len(df.index)):\n",
    "        \n",
    "        #if the predicted class is 4 and the actual class is 2, increment the number of erroneous B\n",
    "        #this corresponds to my algorithm thinking it's malign when it's really benign\n",
    "        if((df.iloc[n, 11] == 4) and (df.iloc[n, 10] == 2)):\n",
    "            errorB_count += 1\n",
    "            \n",
    "        #if the predicted class is 2 and the actual class is 4, increment the number of erroneous M\n",
    "        #this corresponds to my algorithm thinking it's benign when it's really malign\n",
    "        if((df.iloc[n, 11] == 2) and (df.iloc[n, 10] == 4)):\n",
    "            errorM_count += 1\n",
    "       \n",
    "        #count the total number of malign tumors predicted by my algorithm\n",
    "        if(df.iloc[n, 11] == 4):\n",
    "            totalPredM += 1\n",
    "        \n",
    "        #count the total number of benign tumors predicted by my algoritm\n",
    "        if(df.iloc[n, 11] == 2):\n",
    "            totalPredB += 1\n",
    "            \n",
    "        if(df.iloc[n, 10] == 2):\n",
    "            totalB += 1\n",
    "        else:\n",
    "            totalM += 1\n",
    "            \n",
    "        \n",
    "    \n",
    "    #calculate the error rates based on the formulas given in the prompt\n",
    "    errorB = errorB_count / totalPredB\n",
    "    errorM = errorM_count/totalPredM\n",
    "    total_error = (errorB_count + errorM_count) / (totalPredB + totalPredM)\n",
    "    print(totalB, totalM)\n",
    "    print(totalPredB, totalPredM)\n",
    "    #return the error rates to be displayed in the main function\n",
    "    return errorB, errorM, total_error\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    #suppress scientific notation for both pandas and numpy printing \n",
    "    np.set_printoptions(suppress = True)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    #pred_class_list keeps track of the predicted class of each of the rows of the df\n",
    "    pred_class_list = []\n",
    "    \n",
    "    #cluster variables\n",
    "    my_cluster2 = []\n",
    "    my_cluster4 = []\n",
    "    actual_cluster2 = []\n",
    "    actual_cluster4 = []\n",
    "    #read the csv into a dataframe\n",
    "    df = pd.read_csv('breast_cancer_wisconsin-1.csv', na_values = '?')\n",
    "    \n",
    "    #rename the 'scn' column to ID to match the desired output\n",
    "    df.rename(columns = {'scn' : 'ID'}, inplace = True)\n",
    "    \n",
    "    #replace all the missing values with the median value of the a7 column\n",
    "    df['a7'] = df['a7'].fillna(df['a7'].median(axis = 0))\n",
    "    \n",
    "    #initialize the means for each cluster\n",
    "    u2, u4 = initialize(df)\n",
    "    \n",
    "    #run up to 1500 times (it won't take that many)\n",
    "    for j in range(1500):\n",
    "        #assign each point to a cluster initially\n",
    "        pred_class = assignment(u2, u4, df)\n",
    "        \n",
    "        #keep track of each list of predicted classes in an array\n",
    "        pred_class_list.append(pred_class)\n",
    "        \n",
    "        #if it has run at least twice, check to see if the predicted class list has changed since the last run\n",
    "        if(j >= 2):\n",
    "            #if the most recent predicted class list is the same as the previous, break the loop\n",
    "            if(pred_class_list[j] == pred_class_list[j-1]):\n",
    "                break\n",
    "                \n",
    "        #add the Predicted Class column to our dataframe\n",
    "        df['Predicted Class'] = pred_class\n",
    "        \n",
    "        #recalculate the means\n",
    "        u2, u4 = recalculation(df, u2, u4)\n",
    "        \n",
    "    #calculate the error rates        \n",
    "    errorB, errorM, total_error = errorRate(df)\n",
    "    \n",
    "    #display the error rates rounded to 3 decimals and displayed as percents rather than decimals\n",
    "    print(\"Error B: \" + str(round(errorB * 100, 3)) + \"%\\t\\tError M: \" + str(round(errorM * 100, 3)) +\"%\\t\\tTotal Error: \" + str(round(total_error * 100, 3)) + '%')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #commented out the display portion from part 2 so you wouldn't have to look through that again\n",
    "    #print in the format of the desired output\n",
    "    print(\"---------------------------------------Final Means-------------------------------------------\")\n",
    "    \n",
    "    #I chose to round to 12 decimal places because that's the number that would have the output fit nicely on one line\n",
    "    #in my Jupyter notebook. I do no rounding in calculations, just in display. \n",
    "    \n",
    "    #FOR THE TA/PROFESSOR, if you've looked this far, you can see I updated the display to include a10 after I had submitted P2 :(\n",
    "    print(\"mu2: \", *u2[1:10].to_numpy().round(12))\n",
    "    print(\"mu4: \", *u4[1:10].to_numpy().round(12))\n",
    "    print('\\n')\n",
    "    print(df[['ID', 'class', 'Predicted Class']].head(20))\n",
    "       \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "458 241\n",
    "463 236\n",
    "Error B: 2.376%\t\tError M: 6.78%\t\tTotal Error: 3.863%\n",
    "---------------------------------------Final Means-------------------------------------------\n",
    "mu2:  2.956331877729 1.325327510917 1.443231441048 1.364628820961 2.120087336245 1.336244541485 2.100436681223 1.2903930131 1.063318777293\n",
    "mu4:  7.195020746888 6.572614107884 6.560165975104 5.547717842324 5.298755186722 7.572614107884 5.979253112033 5.863070539419 2.589211618257\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
